{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Pelé\n",
    "- Diego Maradonna\n",
    "- Johan Cruyff\n",
    "- Roberto Carlos\n",
    "- Franz Beckenbaur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "UPDATED FROM PROPOSAL!\n",
    "\n",
    "You should have obtained and cleaned (if necessary) data you will use for this project.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_year</th>\n",
       "      <th>case_status</th>\n",
       "      <th>case_submitted</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>emp_name</th>\n",
       "      <th>emp_city</th>\n",
       "      <th>emp_state</th>\n",
       "      <th>emp_zip</th>\n",
       "      <th>emp_country</th>\n",
       "      <th>job_title</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_level</th>\n",
       "      <th>wage_from</th>\n",
       "      <th>wage_to</th>\n",
       "      <th>wage_unit</th>\n",
       "      <th>work_city</th>\n",
       "      <th>work_state</th>\n",
       "      <th>emp_h1b_dependent</th>\n",
       "      <th>emp_willful_violator</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>LAKELANDS NEPHROLOGY, PA</td>\n",
       "      <td>GREENWOOD</td>\n",
       "      <td>SC</td>\n",
       "      <td>29646</td>\n",
       "      <td>USA</td>\n",
       "      <td>NEPHROLOGIST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>SC</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>34.178172</td>\n",
       "      <td>-82.379015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-03-21</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>UNIVERSITY OF IDAHO</td>\n",
       "      <td>MOSCOW</td>\n",
       "      <td>ID</td>\n",
       "      <td>83844</td>\n",
       "      <td>USA</td>\n",
       "      <td>POST DOCTORAL FELLOW</td>\n",
       "      <td>...</td>\n",
       "      <td>Level I</td>\n",
       "      <td>47507.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>ABERDEEN</td>\n",
       "      <td>ID</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>42.944078</td>\n",
       "      <td>-112.838326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>XPO SUPPLY CHAIN, INC.</td>\n",
       "      <td>HIGH POINT</td>\n",
       "      <td>NC</td>\n",
       "      <td>27265</td>\n",
       "      <td>USA</td>\n",
       "      <td>OPERATION ANALYST</td>\n",
       "      <td>...</td>\n",
       "      <td>Level I</td>\n",
       "      <td>65000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>ABERDEEN</td>\n",
       "      <td>MD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>39.509556</td>\n",
       "      <td>-76.164120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>C AND S WHOLESALE GROCERS, INC.</td>\n",
       "      <td>KEENE</td>\n",
       "      <td>NH</td>\n",
       "      <td>03431</td>\n",
       "      <td>USA</td>\n",
       "      <td>SR. INDUSTRIAL ENGINEER</td>\n",
       "      <td>...</td>\n",
       "      <td>Level II</td>\n",
       "      <td>86988.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>ABERDEEN</td>\n",
       "      <td>MD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>39.509556</td>\n",
       "      <td>-76.164120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>C</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>SANFORD CLINIC</td>\n",
       "      <td>SIOUX FALLS</td>\n",
       "      <td>SD</td>\n",
       "      <td>57117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEMATOLOGIST/ONCOLOGIST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>ABERDEEN</td>\n",
       "      <td>SD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>45.464698</td>\n",
       "      <td>-98.486483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_year case_status case_submitted decision_date  \\\n",
       "0       2017           C     2017-02-06    2017-02-10   \n",
       "1       2017           C     2017-03-21    2017-03-27   \n",
       "2       2017           C     2017-03-17    2017-03-23   \n",
       "3       2017           C     2017-03-10    2017-03-16   \n",
       "4       2017           C     2017-08-04    2017-08-10   \n",
       "\n",
       "                          emp_name     emp_city emp_state emp_zip emp_country  \\\n",
       "0         LAKELANDS NEPHROLOGY, PA    GREENWOOD        SC   29646         USA   \n",
       "1              UNIVERSITY OF IDAHO       MOSCOW        ID   83844         USA   \n",
       "2           XPO SUPPLY CHAIN, INC.   HIGH POINT        NC   27265         USA   \n",
       "3  C AND S WHOLESALE GROCERS, INC.        KEENE        NH   03431         USA   \n",
       "4                   SANFORD CLINIC  SIOUX FALLS        SD   57117         NaN   \n",
       "\n",
       "                 job_title  ...  pw_level  wage_from wage_to  wage_unit  \\\n",
       "0             NEPHROLOGIST  ...       NaN  190000.00     0.0          Y   \n",
       "1     POST DOCTORAL FELLOW  ...   Level I   47507.00     0.0          Y   \n",
       "2        OPERATION ANALYST  ...   Level I   65000.00     0.0          Y   \n",
       "3  SR. INDUSTRIAL ENGINEER  ...  Level II   86988.15     0.0          Y   \n",
       "4  HEMATOLOGIST/ONCOLOGIST  ...       NaN  450000.00     0.0          Y   \n",
       "\n",
       "   work_city work_state  emp_h1b_dependent  emp_willful_violator        lat  \\\n",
       "0  ABBEVILLE         SC                  N                     N  34.178172   \n",
       "1   ABERDEEN         ID                  N                     N  42.944078   \n",
       "2   ABERDEEN         MD                  N                     N  39.509556   \n",
       "3   ABERDEEN         MD                  N                     N  39.509556   \n",
       "4   ABERDEEN         SD                  N                     N  45.464698   \n",
       "\n",
       "          lng  \n",
       "0  -82.379015  \n",
       "1 -112.838326  \n",
       "2  -76.164120  \n",
       "3  -76.164120  \n",
       "4  -98.486483  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all the CSV files\n",
    "csv_files = [\"data/h1b_pt\"+str(i)+\".csv\" for i in list(range(1,9))]\n",
    "\n",
    "# Create an empty list to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file, read it into a DataFrame, and append it to the list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames together into a single DataFrame\n",
    "h1b = pd.concat(dfs, ignore_index=True)\n",
    "h1b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3360810 entries, 0 to 3360809\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   case_year             int64  \n",
      " 1   case_status           object \n",
      " 2   case_submitted        object \n",
      " 3   decision_date         object \n",
      " 4   emp_name              object \n",
      " 5   emp_city              object \n",
      " 6   emp_state             object \n",
      " 7   emp_zip               object \n",
      " 8   emp_country           object \n",
      " 9   job_title             object \n",
      " 10  soc_code              object \n",
      " 11  soc_name              object \n",
      " 12  full_time_position    object \n",
      " 13  prevailing_wage       float64\n",
      " 14  pw_unit               object \n",
      " 15  pw_level              object \n",
      " 16  wage_from             float64\n",
      " 17  wage_to               float64\n",
      " 18  wage_unit             object \n",
      " 19  work_city             object \n",
      " 20  work_state            object \n",
      " 21  emp_h1b_dependent     object \n",
      " 22  emp_willful_violator  object \n",
      " 23  lat                   float64\n",
      " 24  lng                   float64\n",
      "dtypes: float64(5), int64(1), object(19)\n",
      "memory usage: 641.0+ MB\n"
     ]
    }
   ],
   "source": [
    "h1b = h1b.drop(h1b.iloc[:, 25:50], axis=1)\n",
    "h1b.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a bar chart \n",
    "\n",
    "#first, get all samples where the cases were certified and all samples where the cases weren't certified \n",
    "\n",
    "h1b_cert = df.loc[df['case_status'] == \"C\"]\n",
    "h1b_noncert = df.loc[df['case_status'] != 'C']\n",
    "h1b_grouped_year = h1b.groupby('case_year').count()['case_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1b_grouped_year.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m      3\u001b[0m data \u001b[39m=\u001b[39m h1b\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdrop([\n\u001b[0;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39memp_country\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpw_level\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlng\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     ], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m---> 14\u001b[0m data\u001b[39m.\u001b[39;49misnull()\u001b[39m.\u001b[39msum\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\frame.py:6384\u001b[0m, in \u001b[0;36mDataFrame.isnull\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6379\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39misna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   6380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misnull\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   6381\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6382\u001b[0m \u001b[39m    DataFrame.isnull is an alias for DataFrame.isna.\u001b[39;00m\n\u001b[0;32m   6383\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6384\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49misna()\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\frame.py:6376\u001b[0m, in \u001b[0;36mDataFrame.isna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6374\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39misna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   6375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m-> 6376\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49misna(func\u001b[39m=\u001b[39;49misna))\n\u001b[0;32m   6377\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39misna\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\internals\\base.py:143\u001b[0m, in \u001b[0;36mDataManager.isna\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(\u001b[39mself\u001b[39m: T, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mapply\u001b[39;49m\u001b[39m\"\u001b[39;49m, func\u001b[39m=\u001b[39;49mfunc)\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:185\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(obj: \u001b[39mobject\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mbool_] \u001b[39m|\u001b[39m NDFrame:\n\u001b[0;32m    109\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:214\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (np\u001b[39m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna_array(obj, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[0;32m    215\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    216\u001b[0m     \u001b[39m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m obj\u001b[39m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\Users\\akhil\\anaconda3\\envs\\conenv\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:296\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    294\u001b[0m         result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39misna()  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m--> 296\u001b[0m     result \u001b[39m=\u001b[39m _isna_string_dtype(values, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[0;32m    297\u001b[0m \u001b[39melif\u001b[39;00m needs_i8_conversion(dtype):\n\u001b[0;32m    298\u001b[0m     \u001b[39m# this is the NaT pattern\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m iNaT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#h1b.isnull().sum()\n",
    "\n",
    "data = h1b\n",
    "\n",
    "data = data.drop([\n",
    "    \"emp_country\",\n",
    "    \"pw_level\", \n",
    "    \"soc_name\", \n",
    "    \"pw_unit\", \n",
    "    \"lat\", \n",
    "    \"lng\"\n",
    "    ], axis=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.isnull().sum()\n",
    "\n",
    "data_clean = data.replace('-', np.nan).dropna(axis=0)\n",
    "\n",
    "data_clean.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE THE PROPOSAL TIMELINE ACCORDING TO WHAT HAS ACTUALLY HAPPENED AND HOW IT HAS EFFECTED YOUR FUTURE PLANS\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "19b17eba0dbd5e4b8827ab8a6192fc0dff7c2985f63f4f278d5b971ef380745d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
